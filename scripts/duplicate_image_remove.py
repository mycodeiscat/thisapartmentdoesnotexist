# -*- coding: utf-8 -*-
"""duplicate_image_remove.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17q-vNL4HQoKg7907A4SogxPYImqJlMD-
"""

# Commented out IPython magic to ensure Python compatibility.
import hashlib
from matplotlib.pyplot import imread
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# %matplotlib inline
import time
import numpy as np

"""# Removing Duplicate Images Using Hashing"""

def file_hash(filepath):
    with open(filepath, 'rb') as f:
        return md5(f.read()).hexdigest()

import os

os.getcwd()

os.chdir(r'D:\thisapartmentdoesnotexist\data\cleaned\images')
os.getcwd()

file_list = os.listdir()
print(len(file_list))

import hashlib, os
duplicates = []
hash_keys = dict()
for index, filename in  enumerate(os.listdir('.')):  #listdir('.') = current directory
    if os.path.isfile(filename):
        with open(filename, 'rb') as f:
            filehash = hashlib.md5(f.read()).hexdigest()
        if filehash not in hash_keys: 
            hash_keys[filehash] = index
        else:
            duplicates.append((index,hash_keys[filehash]))

print(duplicates)

"""# Delete Files After Printing"""

for index in duplicates:
    os.remove(file_list[index[0]])
